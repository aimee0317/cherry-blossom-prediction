import numpy as np
import pandas as pd 

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import (
    StandardScaler,
)
from sklearn.compose import make_column_transformer

from sklearn.cluster import KMeans
from sklearn.svm import SVR
from sklearn.metrics import silhouette_score


import umap
import altair as alt
import matplotlib.pyplot as plt
from yellowbrick.cluster import KElbowVisualizer


data = pd.read_csv("../data/processed/clean_data.csv")
train_df, test_df = train_test_split(data, test_size=0.3, random_state=42)
numeric_features = [
    "lat",
    "long",
    "alt",
    "tmax",
    "tmin",
    "prcp",
    "agdd_winter",
    "tmax_winter",
    "prcp_winter",
    "co2_percapita",
    "co2_emission",
    "year"
]
target = "bloom_doy"


X_train, y_train = train_df.drop(columns=[target]), train_df[target]


X_train_cluster = X_train.drop(columns = ['country', 'city'])


X_train_cluster


scaler = StandardScaler()
preprocess_X = pd.DataFrame(scaler.fit_transform(X_train_cluster), columns = X_train_cluster.columns)
preprocess_X


model = KMeans(random_state=42)
visualizer = KElbowVisualizer(model, k=(5, 20))

visualizer.fit(preprocess_X)  # Fit the data to the visualizer
visualizer.show();


kmeans = KMeans(n_clusters=11, random_state=42)
kmeans.fit(preprocess_X)
preprocess_X["cluster"] = kmeans.predict(preprocess_X)


values, counts = np.unique(preprocess_X["cluster"] , return_counts=True)
count_df = pd.DataFrame({
    'cluster labels': values,
    'counts': counts
})


alt.Chart(count_df, title = "Some clusters have very few samples").mark_bar().encode(
    x = "cluster labels",
    y = "counts"
)


counts


data_plot = preprocess_X.drop(columns=["cluster"])
fit = umap.UMAP(n_neighbors=11,n_components=3, min_dist=0.1, metric='euclidean', random_state=42)
u = fit.fit_transform(data_plot)
color = kmeans.labels_
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(u[:,0], u[:,1], u[:,2], c= color, s=90, cmap="twilight", edgecolors="k", linewidths=0.1)
plt.title("UMAP 3D Visualization of Clusters", fontsize=18);
plt.savefig("../results/cluster.svg")


y_train_new = pd.DataFrame(y_train).reset_index()


n_clusters=11
model = SVR(C=1000, epsilon=1)
cluster_svr = []

for i in range(n_clusters):
    cluster_X = preprocess_X[preprocess_X['cluster'] == i]
    index = np.array(preprocess_X[preprocess_X['cluster'] == i].index)
    lookup = y_train_new.loc[index]
    cluster_y = np.array(lookup['bloom_doy'])
    cluster_svr.append(model.fit(cluster_X.drop(columns = ['cluster']), cluster_y))


X_test, y_test = test_df.drop(columns=[target, 'country', 'city']), test_df[target]


preprocess_X_test = pd.DataFrame(scaler.fit_transform(X_test), columns = X_test.columns)


result = []
clusters_pred = kmeans.predict(preprocess_X_test)
for i, j in enumerate(clusters_pred):
    result.append(cluster_svr[clusters_pred[i]].predict(pd.DataFrame(preprocess_X_test.loc[j]).T))
pred = pd.DataFrame(result, columns = ["y_test_pred"]) 
pred["cluster"] = clusters_pred
pred


y_test_result = pd.DataFrame(y_test).reset_index().drop(columns = ['index'])
results = y_test_result.join(pred)
results['difference'] = results['y_test_pred'] - results['bloom_doy']
results


rmse = (sum(results["difference"]**2) / len(results))**0.5
rmse
